{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:00.242035Z",
     "start_time": "2019-08-13T23:47:44.691942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan 2019-08-14 \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "konlpy 0.5.1\n",
      "tensorflow 1.13.1\n",
      "matplotlib 3.1.0\n",
      "imblearn 0.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a Chan -d -v -p numpy,pandas,sklearn,konlpy,tensorflow,matplotlib,imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:01.739174Z",
     "start_time": "2019-08-13T23:48:00.248030Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.489746Z",
     "start_time": "2019-08-13T23:48:01.744172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>url_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>헐</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>제시</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이거인 듯</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 comment  url_id  label\n",
       "0                     ㅜㅜ      77      0\n",
       "1  ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ      17      0\n",
       "2                      헐      52      0\n",
       "3                     제시      75      0\n",
       "4                  이거인 듯      18      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame()\n",
    "for i in range(1,9):\n",
    "    print(i)\n",
    "    dump = pd.read_csv(\"../../data/labeled ({}).csv\".format(i), engine='python')\n",
    "    datasets = pd.concat([datasets, dump])\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.539716Z",
     "start_time": "2019-08-13T23:48:02.503739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      "comment    23999 non-null object\n",
      "url_id     24000 non-null int64\n",
      "label      24000 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 750.0+ KB\n"
     ]
    }
   ],
   "source": [
    "datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.562704Z",
     "start_time": "2019-08-13T23:48:02.544716Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.comment.fillna('NULL',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.593686Z",
     "start_time": "2019-08-13T23:48:02.583692Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.623667Z",
     "start_time": "2019-08-13T23:48:02.600682Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.label = datasets.label.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:02.696630Z",
     "start_time": "2019-08-13T23:48:02.628669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04641666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[datasets.label ==1])/ len(datasets) # 유해한 레이블의 데이터가 많이 부족함 데이터 편향ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T15:38:19.687895Z",
     "start_time": "2019-08-06T15:38:19.677899Z"
    }
   },
   "source": [
    "# Tokenize\n",
    "## 형태소분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.486007Z",
     "start_time": "2019-08-13T23:48:02.701626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bd967fc6be19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmorp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misJVMStarted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mjvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0moktJavaPackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kr.lucypark.okt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\konlpy\\jvm.py\u001b[0m in \u001b[0;36minit_jvm\u001b[1;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     64\u001b[0m         jpype.startJVM(jvmpath, '-Djava.class.path=%s' % classpath,\n\u001b[0;32m     65\u001b[0m                                 \u001b[1;34m'-Dfile.encoding=UTF8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                                 '-ea', '-Xmx{}m'.format(max_heap_size))\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please specify the JVM path.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_core.py\u001b[0m in \u001b[0;36mstartJVM\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0m_jpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignoreUnrecognized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvertStrings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_core.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0m_jclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0m_jobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0m_jtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0m_java_lang_Class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"java.lang.Class\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_java_ClassLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.ClassLoader'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetSystemClassLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_java_lang_throwable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_java_lang_RuntimeException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_JClassNew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJClass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m_JClassNew\u001b[1;34m(arg, loader, initialize)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_JCLASSES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_JCLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_JClassFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjavaClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m_JClassFactory\u001b[1;34m(name, jc)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;31m#   before we can access the class structures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_java_lang_Class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDeclaredClasses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetModifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m_JClassNew\u001b[1;34m(arg, loader, initialize)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_JClassNew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_java_lang_Class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "morp = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.498001Z",
     "start_time": "2019-08-13T23:47:46.569Z"
    }
   },
   "outputs": [],
   "source": [
    "morped = [morp.morphs(_, norm=True, stem=True) for _ in tqdm(datasets.comment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.500000Z",
     "start_time": "2019-08-13T23:47:46.788Z"
    }
   },
   "outputs": [],
   "source": [
    "morped[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "최빈 형태소에 대한 단어사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.502998Z",
     "start_time": "2019-08-13T23:47:47.165Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "pad_id = 0\n",
    "oov_id = 1\n",
    "index_offset = 1\n",
    "\n",
    "def make_vocab(sentences):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    for sent in sentences:\n",
    "        word_counter.update(sent)\n",
    "\n",
    "    most_common = word_counter.most_common()\n",
    "    print(\"고빈도 단어:\")\n",
    "    for k, v in most_common[:10]:\n",
    "        print(k, \": \", v)\n",
    "\n",
    "        vocab = {\n",
    "        '<PAD>': pad_id,\n",
    "        '<OOV>': oov_id\n",
    "        }\n",
    "    for i, (word, cnt) in enumerate(most_common, start=index_offset+1):\n",
    "        vocab[word] = i\n",
    "        if len(vocab) >= vocab_size:\n",
    "            break\n",
    "\n",
    "    return vocab\n",
    "\n",
    "word_index = make_vocab(morped)\n",
    "word_inverted_index = {v:k for k, v in word_index.items()}\n",
    "\n",
    "print(\"\\n단어 사전:\")\n",
    "for i in range(0, 10):\n",
    "    print(i, word_inverted_index[i])\n",
    "\n",
    "print(\"\\n단어 사전 크기: \", len(word_index))\n",
    "\n",
    "# # vocab save\n",
    "# with open('./vocab/vocab_index.pickle', 'wb') as f:\n",
    "#     pickle.dump(word_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open('./vocab/vocab_inverted_index.pickle', 'wb') as f:\n",
    "#     pickle.dump(word_inverted_index, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.505997Z",
     "start_time": "2019-08-13T23:47:47.343Z"
    }
   },
   "outputs": [],
   "source": [
    "def index_to_text(indexes):\n",
    "    return ' '.join([word_inverted_index[i] for i in indexes])\n",
    "\n",
    "def text_to_index(tokens):\n",
    "    indexes = []\n",
    "    for tok in tokens:\n",
    "        if tok in word_index:\n",
    "            indexes.append(word_index[tok])\n",
    "        else:\n",
    "            indexes.append(oov_id)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "print(\"원본: \", morped[0])\n",
    "ids = text_to_index(morped[0])\n",
    "print(\"문자 -> 숫자: \", ids)\n",
    "print(\"숫자 -> 문자: \", index_to_text(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.509995Z",
     "start_time": "2019-08-13T23:47:47.675Z"
    }
   },
   "outputs": [],
   "source": [
    "x_variable = [text_to_index(_) for _ in morped]\n",
    "\n",
    "sentence_size = 10\n",
    "x_padded = sequence.pad_sequences(x_variable,\n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.511992Z",
     "start_time": "2019-08-13T23:47:47.854Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    val = plt.plot(history.epoch, history.history['val_loss'],\n",
    "                 '--', label='Test')\n",
    "    plt.plot(history.epoch, history.history['loss'], color=val[0].get_color(),\n",
    "           label='Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.514990Z",
     "start_time": "2019-08-13T23:47:48.002Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 데이터 클래스 불균형 문제 해결하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.517990Z",
     "start_time": "2019-08-13T23:47:48.407Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upsampling\n",
    "- 딥러닝은 데이터가 많을수록 좋다.\n",
    "- 보다 많은 데이터 사용을 위해 upsampling을 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.520987Z",
     "start_time": "2019-08-13T23:47:48.805Z"
    }
   },
   "outputs": [],
   "source": [
    "up_X, up_y = RandomOverSampler().fit_resample(x_padded, datasets.label)\n",
    "up_X_train, up_X_test, up_y_train, up_y_test = train_test_split(up_X, up_y)\n",
    "\n",
    "# 총 데이터 수 , 1 레이블 데이터 수\n",
    "len(up_y), up_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.523986Z",
     "start_time": "2019-08-13T23:47:49.024Z"
    }
   },
   "outputs": [],
   "source": [
    "model_up = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 10),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.529982Z",
     "start_time": "2019-08-13T23:47:49.233Z"
    }
   },
   "outputs": [],
   "source": [
    "model_up.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "history = model_up.fit(up_X_train,\n",
    "          pd.get_dummies(up_y_train),\n",
    "          epochs=5,\n",
    "          validation_data=(up_X_test, pd.get_dummies(up_y_test))\n",
    "         )\n",
    "plot_loss(history)\n",
    "test_loss, test_acc = model_up.evaluate(up_X_test, pd.get_dummies(up_y_test))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.531982Z",
     "start_time": "2019-08-13T23:47:49.443Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.apply_along_axis(index_to_text, 1, up_X_test))\n",
    "result['predict'] = model_up.predict_proba(up_X_test)[:,1] # 유해하다고 판별할 확률\n",
    "print('전체채팅수{}, 유해채팅수{}'.format(len(result),len(result[result.predict>0.5])))\n",
    "result[result.predict>0.5].head(10)\n",
    "result['label'] = up_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.534979Z",
     "start_time": "2019-08-13T23:47:49.635Z"
    }
   },
   "outputs": [],
   "source": [
    "# result.to_csv('../../data/cnn_result.csv', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.536978Z",
     "start_time": "2019-08-13T23:47:50.019Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.538978Z",
     "start_time": "2019-08-13T23:47:50.175Z"
    }
   },
   "outputs": [],
   "source": [
    "recall_score(up_y_test, model_up.predict_classes(up_X_test)),\\\n",
    "accuracy_score(up_y_test, model_up.predict_classes(up_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.542976Z",
     "start_time": "2019-08-13T23:47:50.345Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_up.save('../model/cnn_oversample.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.544973Z",
     "start_time": "2019-08-13T23:47:50.691Z"
    }
   },
   "outputs": [],
   "source": [
    "down_X, down_y = RandomUnderSampler().fit_resample(x_padded, datasets.label)\n",
    "down_X_train, down_X_test, down_y_train, down_y_test = train_test_split(down_X, down_y)\n",
    "\n",
    "# 총 데이터 수 , 1 레이블 데이터 수\n",
    "len(down_y), down_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.547972Z",
     "start_time": "2019-08-13T23:47:50.855Z"
    }
   },
   "outputs": [],
   "source": [
    "model_down = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 10),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.549972Z",
     "start_time": "2019-08-13T23:47:51.025Z"
    }
   },
   "outputs": [],
   "source": [
    "model_down.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "history = model_down.fit(down_X_train,\n",
    "          pd.get_dummies(down_y_train),\n",
    "          epochs=5,\n",
    "          validation_data=(down_X_test, pd.get_dummies(down_y_test))\n",
    "         )\n",
    "plot_loss(history)\n",
    "test_loss, test_acc = model_down.evaluate(down_X_test, pd.get_dummies(down_y_test))\n",
    "print('Test Recall:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.551970Z",
     "start_time": "2019-08-13T23:47:51.200Z"
    }
   },
   "outputs": [],
   "source": [
    "#recall\n",
    "recall_score(down_y_test, model_down.predict_classes(down_X_test)), \\\n",
    "accuracy_score(down_y_test, model_down.predict_classes(down_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.554968Z",
     "start_time": "2019-08-13T23:47:51.361Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.apply_along_axis(index_to_text, 1, down_X_test))\n",
    "result['predict'] = model_down.predict_proba(down_X_test)[:,1] # 유해하다고 판별할 확률\n",
    "print('전체채팅수{}, 유해채팅수{}'.format(len(result),len(result[result.predict>0.5])))\n",
    "result[result.predict>0.5].head(10)\n",
    "result['label'] = down_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.557966Z",
     "start_time": "2019-08-13T23:47:51.649Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예측 실패 채팅\n",
    "result[model_up.predict_classes(up_X_test) != up_y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.559965Z",
     "start_time": "2019-08-13T23:47:52.148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예측 애매한 채팅\n",
    "result[model_up.predict(up_X_test)[1]>0.4 and model_up.predict(up_X_test)[1]<0.6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.563964Z",
     "start_time": "2019-08-13T23:47:52.510Z"
    }
   },
   "outputs": [],
   "source": [
    "test_chat = \"시1123123123발\"\n",
    "test_id = text_to_index(morp.morphs(test_chat, norm=True,stem=True))\n",
    "\n",
    "sentence_size = 10\n",
    "x_padded_temp = sequence.pad_sequences([test_id],\n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "print(morp.morphs(test_chat, norm=True,stem=True)[:10])\n",
    "model_up.predict(x_padded_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T23:48:19.565963Z",
     "start_time": "2019-08-13T23:47:53.331Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_down.save('../model/cnn_undersample.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- 형태소별 Tokenize 말고 한글 자모별 Tokenize 하여 실험해보기\n",
    "- CNN layer / Parameter 변경시켜보기\n",
    "- 예측 결과 검정하기\n",
    "    - Attention 이용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
