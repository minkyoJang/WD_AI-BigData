# 박천복님
- 주로 NLP 하심
- 액티베이션 강화: 미국 및 영국쪽에서 보면(악성판단 딥 페이크등) 엘사 게이트. 유투브에도 유명한게 있는데 유투브 영상중에서 유투브 키즈가 애들이 많이보는데 어린이영상 올리면 많은 조회수가 나와서 그런 영상을 보기 시작함. 그래서 생각한 방법이 어린이 영상으로 돈 벌겠다 생각했는데 사람들이 악의적인 영상을 올림. 예를 들면 엘사가 또응ㄹ 싸고 스파이더맨이 강간.근데 제목에 엘사가 들어가면 자동 추천이 되어 아이들도 보게됨. 그럼 그 영상ㄴ을 본 아이들이 충격을 받고 심리적으로도 안 좋은게 생길 수 있어 유투부에서 엘사 게이트라고 불릴만한 그런 상황이 발생. (게이트= 큰 상황) 딥페이크도 있지만 영국등에서 큰 이슈가 되었던 것이 엘사 게이트. 이 용어를 이용하여 보고서에도 작성하면 좋을 듯
- 일단 하나씩 이야기해볼까요? 이슈 먼저 이야기 해주시는게 좋을 듯한데. 
- 일단 보고 말씀해주실게요

#박천복님 이미지
-1. 전처리하면서 정신적으로 힘들거같아요. 저는 해봤거든요. 사람들의 채팅 데이터 NC에서 해봤는데 정신이 아파서 욕도 많고 그래서 힘들었는데. 일단은 그러면서 욕설들이 좀 문제가 되는건 다양한 식으로 나온다는거에요. 욕설 필터링 개선인가요? 뭐가 문제가 되나면 말씀하신 시읍 비읍으로 자음일수도 ,된소리 발음할수도 있어서 많은데. 이 경우 하나의 토큰으로 보는게 안 좋고 서브워드기반으로 토큰으로 보는게 좋아요

# 서브워드기반 토큰
-어떤 워드에 서브 기반으로 토큰을 하는 방식
- 아마 이 방식을 형태소기반으로 하신거 같아요. 잘 되세요? 그런 토큰화가 제일 중요해요. 앤엘피에서는 전처리가 전체적인 성능 좌우해요. 
- 보캐블러리가 많이 존재하면 그게 오버피팅만 만들게 되어서 이 토크나이즈가 제일 중요하죠 

# 얼만큼 토크나이즈 나와요?
- 성능 안나오면 카카오. 카카오 형태소 분석기. 그게 더 좋아요
-  konlpy로 하면 뒤지/뒤진다/ 등을 다 다르게 뽑더라구요. 
	-> 아마 토크나이즈를 잘 못하면 모델 무엇을 쓰든 다 망할거에요. 

#토크나이즈 추천
->1. 카카오 형태소 분석기
->2. 단어를 유니코드화 해요. bpe(byte pair encoding:서브워드 기반으로 나누는것)기반의 임베딩. 
	- 유니코드화하면: 간다/간당/간달 등에서 앞 부분이 같은 모습이 나타나서 할 수 있음
	- 그러나 유니코드형식이라서 디코드 방식이 필요하기도 함.
	- BPE라는 논문을 일단 읽는것도 추천. 혹은 인터넷 사이트에서 검색하는것 추천.

# 정리
- 데이터 전처리 빡세다
- 하는것 대비해서 성과가 없어보일수있는데 그 이유가 전처리 때문일 수 있으니 이부분 어필하고, 여기서 다양한 세팅도 했다는거 어필하는게 좋을 듯. 
- 전처리 추천 (konlpy, kakao, bpe:한국어를 유니코드화해서 임베딩하여 진행)

# 결국
- 인풋: 하나의 채팅
- 아웃풋: 유해 여부에 따른 0,1
- 사전기반으로 하는 경우가 하나의 베이스라인, 딥러닝으로 하는게 또 하나의 제안하는 방법이겠죠. 

# 문어체 및 구어체 
- 이 프로젝트가 어려운 점은 한국어가 어려워서 어려울거에요.
- 문어체가 구어체와 같지 않다는 이슈가 있을 것 같은데, 근데 여기 대부분의 단어가 전부 구어체이니까 은근히 그 문제가 적을 수 있어요

#레이블링은 어떻게 하셨어요?
- 직접했어요. 5만개를 했다고 하면  또하나의 이슈
- 레이블링을 하면 사실 한명이 상이 하면 안되어요. 하나의 레이블링을 세명이 해서 다수결에 의해 레이블링된 결괄를 진행하게끔해야해요.
- 혼자 고민해서 유해하다고 할 수는 없죠. 프로 불편러가 있을수도 있고, 이미 내 삶이 욕설인데 저정도 쯤이야라고 생각하는 사람도 있으니까. 레이블링이 노이즈 할 수 있어서 원래는 버절트를 하고 컨트리부션(?)으로 할 수도 있어요. 
- 데이터 셋에 대한 공격에 반박을 해야하니까
- 그리고 분석에 있어서 크롤링을 할때 단순히 150만개, 5만개도 있찌만 통계적으로해서. 유해도가 얼만큼이고 아닌지 얼만큼인지를 (95:5) 정도라고 알려주는게 좋았어요. 근데 9:1이면 유해도가 적은게 문제가 될 수 있죠


# 애큐러시로만 측정을 하면 안되겠죠. 그래서 어떤 매져 생각했어요?
- 현재 다운샘플링으로 5대5 맞춰놓고 트레이닝만 했는데 유해에 대해서 .. 70프로. 
- 파지티브 트루 .. 리콜이 76프로. 
- 

# 리콜 보는거 정말 좋아요. 
- 리콜 프레시젼봐야하고 애큐러시는 보면 안되어요. (애큐러시만 보면 아마추어)
- 애큐러시 아예 안보는건 또 아닌데 일단은.
- 프레시젼 리콜하나는 꼭 보고** . 리콜은 프로토셋 리콜. 얼마나 ..? 많이 올 수록 좋잖아요...? 
- 그런식으로 썰을 풀면서 사람들 이해시키는게 좋아요
- 바이너리라서 roc라는 커브도 보는게 좋아요 ****

#모델?
- CNN

# 굳이 왜 CNN만 사용하시려고 하나요?
- 사용해본게 CNN.
- 컨볼류션은 나쁜 선택은 아니에요. 그런데 샌텐스 클래시피케이션에 RNN도 있거든요. 그런 오픈소스 코드를 사용하는게 좋을거같아요**
- convolution cnn만 했다고 하면(이걸로 수상을 하겠다는 목적인지 수료 목적인지 모르겠는데 더 잘해서 수상하고 싶다고 한다면  rnn 및 attention으로 보여주면 좋죠)

# 어탠션
- 특정 단어에 무엇을 보았는지 알 수가 있어요.
- 욕설이라고 했는데 욕설에 어탠션을 했는지 보고 싶을거잖아요
- 그런거 보여주면 있어보이겠죠. 그런게 어탠션이고
- 개인적으로는 


# 딥러닝 계층에 어탠션만?
- 네 하나만 추가해서 기존 cnn 앞단에서 하고 마지막 플리커립 레이어 하기전에 어탠션 넣어서 해도 되어요
- 그런 노역이 가능할지 아니면 저 공개된 코드에 맞출지는 한번 해보시고.


#CNN으로 어탠션은 되나요
- 네 될 수도 있기는 한데.

# 강력한 무기: 어탠션★
- 지금 수상을 한다고 하면 presentation에서 강력한 무기가 필요해요
- 그게 결국 모델쪽이 흥미로워요. 한게 없지만 시각적으로 보여줄수 있는게 이 팀은 어탠션
- 택스트가 이거 넣고 저거 나왔다는거라서 이미지보다 흥미가 적어요
- 그래서 사람이 볼때 별로 흥미롭지 않아서, 이렇게 봐서 유해했다는게 보여주는게 더 이쁜거죠
- 그런 이쁜 이그젬플. 그런 부분들을 가져오는게 좋을거 같고.

# 논문
- 5페이지쯤에 빨간 하이라이트 있는데, (classification부분)
- 그런 식으로 느낌이 나오게 하는거에요. 

# 특정 단어
-특정 용어 얼마나 많은지 보여주면 좋을 것 같고

# 찬 궁금한 점
- 인밸런스하다고 말씀드렸는데 그게 언더 샘프링/오버샘플링 하는지 모르겠어서 일단 돌려서 성능 좋은거 선택하려는데?
-> 그게 현실적이죠 다른 트릭을 할수 있지만 언더/오버는 뭔 기법 쓸지 보다는. 차라리 어탠션 얹는게 더 좋을거 같아요. 이 피피티에서 보면 언더/오버샘플링이 사실 한 문장이에요. 
-> 이제는 시간이 없으니까 프래잰테이션에서 데모만 보여주는게 아니라 '왜'그렇게 나왔는지를 보여줘야할떄**


# hci 쪽에 유명한 학회하나
- 레이블링 시스템. 
- 이 논문 읽고 이터레티브 어탠션. 

#이터레티브 어탠션.(??)
- 특정 워드가 네거티브일거 같으면 사용자가 가이드해주는것. 레이블링해서
- 이거한번해보면 좋을거 같아요. 읽어보시고
- 모델 안 기니까 읽어보고.
- 디자인 팁이 많으니까 백그라운등 아이디어 부분은 적당히 보면서 가져가는게 좋을 듯

# 찬 질문: 레이블링 더 해야하나요?
- 하면 좋은데 일단은.

# 우선순위
1. 피티를 잘할 생각을 해야해요. 완결성. 
- 정확한 매져들 이 필요해요. 
- 매져들 다양하게 실험하고 검증한거 보여주고
- 어떤 메세지 있는지 이야기해주기
2. 어탠션 모델
- 단순히 이 결과를 보여줄게 cnn 모델이라면 90프로의 성능이 나온게 끝이에요
- 프레젠테이션에서 감독자라고 하면 이미지분류에 비해 텍스트는 감동이 덜해요
- 이미지 쪽에서도 이부분을 넣었다라고 하는 팀이 있으니, 그런식으로 텍스트도 넣을 필요가 있어요
- 어느 부분이 중요하고 어디를 어탠션했는지 보여주는 순간 이쁮
- 이게 긍/부정문장인데 어디를 보고 그렇게 했는지. 
3. 레이블링
- 엄밀성을 위해 레이블링 헀다
- 레이블링 동의하는 식으로 했다. 하는 식으로 썰을 풀면 더 좋을듯
** .. 알고리즘 평가자도 있지만 nlp쪽은 오히려 글자뿐이라서 땡김이 덜하기에 썰을 잘 푸는게 필요해요. 

 

#진행방향
-1. 전처리(2개의 팀 나눠서 전처리 vs 딥러닝)
-  2명은 전처리할 수 있게 전처리 팀 구성하기(다양한거 하세요)
> 모델 돌리기
> 어탠션 돌려 성공하기
> 시간이 남는다면 데이터 자체에 있는 노이즈를 어떻게 제거하는지.
-2. UI 어떻게 보여줄지
- 이거 주신거 참고하세요. 하이라이트 하는 식으로

#질문: 어탠션은 어탠션 기반의 모델을 사용하라는거죠?
- 그렇고 아까 보여준 코드가 많이 나와있으니 보시면 좋을거 같아요.
- 어탠션 뽑아서 시각화할 생각을 하셔야해요.
- 시간이 없긴하거든요. 10일이면 할 수 있어요. 
- 여기서 수상목적이 있으면 몇일 밤새면 되고 5일하셔도 되어요.

# 노이즈
- 앙상블링
- 데이터 자체의 갯수를 늘리기
-근데  데이터가 많아서 좋을 수 있지만 노이즈 많은 데이터는 안 좋겠죠. 

# 질문: 지금거에서 어탠션만 얹어도 되어요?
- 근데 그런 코딩을 할 수 있을지 모르겠어요
- 남의 코드를 가져와서 하는게.. 더... 개인의..성향이긴하지만.. 챌린지를 원한다면야

- 딥러닝 개발 처음이라고 하면 그거 나름대로 문제가 있는거거든요. 근데 이것까지하면 많죠. gui도 개발하고 아마 개발 프로세스는 할 일이 많은데 일단 그거 하고. 딥러닝 개발이 어려우면 통계 및 전처리로 해야하고. 팀장은 팀원 강점에 맞게 일 분배하셔야하고. 
- 어탠션 3일 안에 끝내고 학습을 1-2일 안에 끝내야 시각화가 나올 수 있죠
-어탠션 좋은 예제 몇 개만 보여주면 됩니다.


#질문: konlpy, kakao등 했는데 원하는 만큼 토큰을 못 만들면...?
- 토큰은 현재 한국어의 어려움이니까 못 만들어요
- 거기서 최선을 뽑아요

# 질문; BP로 나누면 자소 단위인가요?
- 자소보다는 크죠. 그래서 형태소 분석이라고 하죠. 어근/어미. 이런 식으로


# 지금까지 한건데 어떤지 확인해보고 싶어요
- 리콜이 진짜 유해한거를 유해하다고 판별하는 그거거든요.진짜 유해한거 유해하다고 판별할 확률인데 현재 95, 어큐러시가 75, 전체가 87퍼센트 정도 나오는데 이건 어떤건지.
- 근데 95프로는 위험한데. 지금 보면 애매한게 맞아요
- 지금 언더 샘플링하면서 모델은. 조금만 유해라고 생각하면 유해라고 하니까 13프로 날린거죠. 저거는 사실은 보면 리콜하고 프레션 고려하는게 f1 score. 37 저 모델이라서 맨 밑에 있거나 위에 있는게 더 좋은모델(?)
- 정책에 따라 다르긴한데. 
- 언더샘플링과 오버샘플링한 모델에 앙상블을 하는거에요**

#앙상블
- 긍정주의자와 비관주의자 한명씩 두고 아웃풋을 조합하는거죠
- 유저가 define할수 있다라고 할 수도 있는거죠.
- 지금 애매한거 맞아요.(?)

#의료 비유
- 의료쪽 문제고 같은게 결국 사람이 암에 걸리는게 크리티컬하고 ,암에 걸린 사람을 걸리지 않았다 하는게 크리티컬. 그래서 거기에 가중치를 두어서 하는데 여기서도 할 수 있겠죠. 정책에 따라 다르겠지만. 근데 그러면 너무나 많은 사람이 블락이 되고 다른쪽의 리콜은 떨어질 수도 이쓰니까
- 긍정이라고 생각하는 사람을 부정이라고 할 수 있으니 프레시젼이 떨어질 수 있는데 그런 정책을 원하는 사람이 있을 수 있으니.
- 부정적과 긍정적인 모델이 각각 있고 따로 학습해서 할 수 있게끔하는게 좋을거같아요
- 결국 머신러닝에서  hci 느낌나요. 사용자의 케이스를 넣어보는게 좋아요. 프레젠테이션에서는 사용자가 이렇게 쓸거라 이렇게 만들었다는 ㅅ'시나리오' 넣는게 좋을 거 같아요.

# 조언이라고 마무리 
- 이거는 제안을 한거고 틀린 걸 수도 있어요. 오늘 모든 조언은 방향일뿐 정답은 아니에요.

# 질문: f1 score 중요하나요?
- precision recall 가진게 f1score니까 그게 좋은 매져일 수 있죠
- f1이 75나 나와요? 왜이렇게 좋아요?(어그먼테이션하고 데이터 중복이 없다고 하는데)
-> 데이터 어그먼테이션 어떻게 했어요?: 워드의 특정 순서를 바꾼거에요? 어떤 토큰을 바꾼다고 생각했어요? 랜덤하게? 워드 안에서의 서브워드들의 토큰을 바꾼다? 센텐스 안의 숫자를 바꾼다? 근데 성능이 좋아진다고요? 왜 그럴까요? 근데 오히려 형태소화가 되면 아까 이야기한것처럼 .. 

# 데이터 어그먼테이션?
- 휴리스틱하게 데이터 어그먼테이션한건데 이거 넣으면 좋은거 같은데 왜 잘 되었는지에 대한 이야기가 나오면 좋을거같아요
- 욕 토큰도 서브워드로 나뉘어져있는데 이게 쪼개서 나뉘어지는순간 다른 단어가 되니까
- 제가 볼 경우에 이거는 애매한 파트가 있는거 같고, 그래서 잘모르겠어요. 오히려 데이터 자체가 적어서 '발'만 나와도 욕이라고 보는거 같아요. 그런 토큰의 조합에 대해 이야기하는거 같으니 논리성이 없는거같아요
- 일단 너무 높게 나오면 의심해보고
- 실제 예제를 넣고 해보는게 좋아요. 숫자만 믿지 말고. 
- 도움이 될 수 있을거 같은데 어떻게 도움이 되었는지 잘 모르겠어요
- 워드간의 토큰을 움직이는게 있는데 얘네들도 적어도 내 위치에서 3 스탭 이상은 가지 않게 제약이 있어요. 더 가면 이상하니까
- 근데 얘는 마음대로 무한대로 움직이는데 잘된다는게 좀 신기한거 같아요
- 모델 관점에서는 오더링이 의미 없다고 볼 수도 있죠. cnn이라서 그런걸 수도 있는거고. 그건 잘 모르겠어요.

# 질문: 지금 현재 해야하는게 라벨링보다는 전처리를 하는게 맞나요
- 지금 그거는 사람이 어떻게 되는지 모르겠어요.
- 개발 시간이 더 많이 없다면 전처리하고 레이블링은 추가하면 되는거니까 우선이 아니라 전처리가 우선되야해요. 그래야 뒤에서 모델링하기 쉬우니까.
- 모델에 대한 코드 하고. 모델 성능 기다리는 동안 레이블링 하면 되는거니까.

#
- 빠르게 어탠션으로 바꾸면 빡세게 진행하게 될거에요
- 이거 맞춰서 시각화 디자인다시해야하니까

#질문; 오픈소스에 시각화도 있나요?
- 카이 프로젝트는 코드 공개 아니에요
- 시각화는 가중치별로만 해주면 되는거에요. 