# keras
-사용
[한글>형태소분석_tagging>단어사전> 모델 CNN]
# 한글은 형태소 분석을 ㅐㅎ야함. 최소 의미단위
- 형태소 분석을 해준 다음(태깅)> 시111발에 대한 '아이디 값'을 구하여 숫자로 매칭 >> 012>> 이후 단어 사전을 만들고> 단어사전을 이용하여 만든 단어로 모델을 넣음> 이떄의 모델은 CNN 

# 현재 데이터가 평향됨

# TOkenize
- 형태소 분석
- 명사/조사/명사등으로 다 쪼개고

# Dictonary
- 최대 5천개의 단어에 대해 진행(한 문장당 최대 5천자)
- 여기 있는 글 중에서 오천개 안에 없는 거슨 그냥 <OOV라고 해서 아웃오브 보케블러리 처리
- 하나의 단어로 생각 안하고 단어 사전에 없다. 기타로 처리.
- 단어벡터를 숫자로 변경하ㅣㄴ다하면 문장의 길이에 따라서 단어 벡터의 길이 달라짐 아이디로 변할떄
- 그래서 패딩으로 채우야하는데. pad_id=0dlrh
- 각 문장에 대해서 카운터를 사용하여 문장이 몇 번 나왔는지 워드 카운팅
- 워드 카운트 해서 most common에 대해서 찾고, 빈도수가 많은 것부터 단어 사전에 넣음 
- 혹은 데이터 자체를 형태소 분석한걸 넣을 수도 있지. 현재 고빈도 다 넣는것. 욕이 있든 없든 상관없이 
- 빈도 높은 5천개를 (데이터셋에서) 형태소를 넣어
	>> 우리가 레이블링한 현재 6천개에 대해서 3421개. 
	>> 현재 ㅋㅋㅋㅋ 을 ㅋㅋ 이렇게 형태소 분석이 변경하여 중복이 되게끔 함

질문)의미 없는 단어가 너무 많은거아냐?
- 그래서 조사 뺄까했는데 다른 곳들도 넣더라구요
- 근데 현재 이 조사들이 필요할거 같을듯. 특히 채팅 데이터라서 조사가 안 맞는게 많음
- ㅅㅂ 같은 것도 


질문) 트레이닝 셋을 만드는거야? 사전을 가져온게 아니라?
0  

# 숫자값으로 변경
 - 문자<>숫자, 숫자<>문자

질문) 단어 사전에 없는것은?
- 오오브이로 진행. 현재 이게 아이디가1임

#패딩
- 각 채팅마다 길이가 달라서 패딩을 해-
- 아까 0번이니까 0번 아이디로 넣고, 센텐스 사이즈가 20
- 케러스 내부 모듈
-즉 20까지는 꽉 채우는것
질문) 왜 20으로 설정했는가?
- 이건 그냥 찬이가 임의로 설정
질문) 이보다 더 많을수도?
- 어차피 이 만크믄 필요없다 해서 자름. 너무 긴거에 맞추면 성능 낮출 수도.

#데이터 스프릸
- 단어길이 20

#모델
- 임베딩하고, 컨볼류션하고, 드랍아웃2번해서 오버피팅 맞추고
- 저기서 32는 씨앤앤 채널의 갯수. (이의 배수가 컴퓨터에 맞다고 배웠대)
- 두께. 패치. 가로세로가 3. 

# 플롯팅 하는 함수
# 어큐런시 보는 함수
# 이진분류해서 옵티마이저 사용. 5번만 돌렸어요. 그렇게 해서 봤더니 그래프 모양 같음ㄴ
- 테스트 정확도가 86프로

# 현재 문제가, 예측 클래스가 0임.
- 1이 없다는 것.
- 예측 결과가 유해하지 않다고 함. 
- 아까 너무 0만 너무 많아서 이런 겨로가가 나온것임

# 그래서 ㄷ데이터 클래스 불균형 문제 해결하려고
- 언더샘플링 오버샘플링으로 너무 많으면 언더 샘플링은 데이터 많으면 랜덤으로 버리고, 오버샘플링은 데이터 적은걸 중복으로 처리
- 근데 딥러닝은 데이터 많을 수록 좋다는 이야기 한다그래서 업샘플링 사용
- 그래서 사용했더니 이제는 1로 찍인게 1/3,2/3
- 나누고 샘플링하고 모델에 넣고 돌려보니 정확도 97프로나오고 정확히 예츠가고
- 플로팅도 이쁘게 되고
- 몇 퍼센트의 확률로 1인지 보려고 했는데 

# 분류가 어려운 것들도 있었음
- 이런건 우리가 다시 직접해서 다시 레이블링 하는 식으로 진행
- 다시 1,0으로 해서
-예측잘못한 것도 있음


# 시111바
- 0.7퍼센트로 욕이라고 나왔음 

# 현재) 비제이 수가 적더라도 많이 하게 했으면 좋을 듯
- 