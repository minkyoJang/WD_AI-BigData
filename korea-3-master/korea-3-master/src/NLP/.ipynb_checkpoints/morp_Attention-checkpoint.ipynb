{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:32.322863Z",
     "start_time": "2019-08-22T01:17:09.000211Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan 2019-08-22 \n",
      "\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "konlpy 0.5.1\n",
      "torch 1.0.1\n",
      "keras 2.2.4\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a Chan -d -p numpy,pandas,konlpy,torch,keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:18:39.190596Z",
     "start_time": "2019-08-22T01:18:39.182600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import konlpy\n",
    "from utils.bp_processing import bp_tokenize\n",
    "from utils.morp_preprocessing import chat_to_morp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:32.804589Z",
     "start_time": "2019-08-22T01:17:32.382830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>url_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>헐</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>제시</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>이거인 듯</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                comment  url_id  label\n",
       "0           0                     ㅜㅜ      77      0\n",
       "1           1  ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ      17      0\n",
       "2           2                      헐      52      0\n",
       "3           3                     제시      75      0\n",
       "4           4                  이거인 듯      18      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.read_csv('../../data/train.csv', encoding='utf-16')\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:38.065578Z",
     "start_time": "2019-08-22T01:17:32.810585Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch.utils.data as data_utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:38.129540Z",
     "start_time": "2019-08-22T01:17:38.070574Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = [[_] for _ in datasets.comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:38.342420Z",
     "start_time": "2019-08-22T01:17:38.134538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4192, 2096)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersampling\n",
    "X, y = RandomUnderSampler().fit_sample(tmp, datasets.label)\n",
    "len(y), sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:38.363406Z",
     "start_time": "2019-08-22T01:17:38.346418Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:17:38.396387Z",
     "start_time": "2019-08-22T01:17:38.369403Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = [_[0] for _ in X_train]\n",
    "X_test = [_[0] for _ in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:22:32.463770Z",
     "start_time": "2019-08-22T01:22:32.432789Z"
    }
   },
   "outputs": [],
   "source": [
    "??chat_to_morp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:21:00.147163Z",
     "start_time": "2019-08-22T01:20:38.037822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3144/3144 [00:19<00:00, 157.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1048/1048 [00:01<00:00, 544.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# bpe tokenizing\n",
    "tokenized_train = chat_to_morp(X_train)\n",
    "tokenized_test = chat_to_morp(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:21:38.977380Z",
     "start_time": "2019-08-22T01:21:38.910418Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = data_utils.TensorDataset(torch.from_numpy(tokenized_train).type(torch.LongTensor),torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
    "BATCH_SIZE = 64\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
    "# return train_loader,x_test_pad,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:21:57.599720Z",
     "start_time": "2019-08-22T01:21:57.551747Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch,keras\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    " \n",
    "EMB_DIM = 6\n",
    "VOCAB_SIZE = 17000\n",
    "class StructuredSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The class is an implementation of the paper A Structured Self-Attentive Sentence Embedding including regularization\n",
    "    and without pruning. Slight modifications have been done for speedup\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, batch_size, lstm_hid_dim, d_a, r, max_len, emb_dim=EMB_DIM, vocab_size=VOCAB_SIZE):\n",
    "        \"\"\"\n",
    "        Initializes parameters suggested in paper\n",
    " \n",
    "        Args:\n",
    "            batch_size  : {int} batch_size used for training\n",
    "            lstm_hid_dim: {int} hidden dimension for lstm\n",
    "            d_a         : {int} hidden dimension for the dense layer\n",
    "            r           : {int} attention-hops or attention heads\n",
    "            max_len     : {int} number of lstm timesteps\n",
    "            emb_dim     : {int} embeddings dimension\n",
    "            vocab_size  : {int} size of the vocabulary\n",
    " \n",
    "        Returns:\n",
    "            self\n",
    " \n",
    "        Raises:\n",
    "            Exception\n",
    "        \"\"\"\n",
    "        super(StructuredSelfAttention,self).__init__()\n",
    "       \n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = torch.nn.LSTM(emb_dim, lstm_hid_dim, 1, batch_first=True)\n",
    "        self.linear_first = torch.nn.Linear(lstm_hid_dim, d_a)\n",
    "        self.linear_first.bias.data.fill_(0)\n",
    "        self.linear_second = torch.nn.Linear(d_a, r)\n",
    "        self.linear_second.bias.data.fill_(0)\n",
    "        self.n_classes = 1\n",
    "        self.linear_final = torch.nn.Linear(lstm_hid_dim, self.n_classes)\n",
    "        self.batch_size = batch_size       \n",
    "        self.max_len = max_len\n",
    "        self.lstm_hid_dim = lstm_hid_dim\n",
    "        self.hidden_state = self.init_hidden()\n",
    "        self.r = r\n",
    "        \n",
    "    def softmax(self,input, axis=1):\n",
    "        \"\"\"\n",
    "        Softmax applied to axis=n\n",
    " \n",
    "        Args:\n",
    "           input: {Tensor,Variable} input on which softmax is to be applied\n",
    "           axis : {int} axis on which softmax is to be applied\n",
    " \n",
    "        Returns:\n",
    "            softmaxed tensors\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    " \n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size)-1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = F.softmax(input_2d)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size)-1)\n",
    "       \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)),Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)))\n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeddings = self.embeddings(x)\n",
    "        outputs, self.hidden_state = self.lstm(embeddings.view(self.batch_size,self.max_len,-1),self.hidden_state)       \n",
    "        x = F.tanh(self.linear_first(outputs))       \n",
    "        x = self.linear_second(x)       \n",
    "        x = self.softmax(x,1)       \n",
    "        attention = x.transpose(1,2)       \n",
    "        sentence_embeddings = attention@outputs       \n",
    "        avg_sentence_embeddings = torch.sum(sentence_embeddings,1)/self.r\n",
    "        \n",
    "        output = F.sigmoid(self.linear_final(avg_sentence_embeddings))\n",
    "        return output,attention\n",
    "\n",
    "       \n",
    "    #Regularization\n",
    "    def l2_matrix_norm(self,m):\n",
    "        \"\"\"\n",
    "        Frobenius norm calculation\n",
    " \n",
    "        Args:\n",
    "           m: {Variable} ||AAT - I||\n",
    " \n",
    "        Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "        return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:22:02.620845Z",
     "start_time": "2019-08-22T01:22:02.564878Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def train(attention_model, train_loader, criterion, optimizer, epochs = 5, use_regularization = False , C=0, clip=False):\n",
    "    \"\"\"\n",
    "        Training code\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            train_loader    : {DataLoader} training data loaded into a dataloader\n",
    "            optimizer       :  optimizer\n",
    "            criterion       :  loss function. Must be BCELoss for binary_classification and NLLLoss for multiclass\n",
    "            epochs          : {int} number of epochs\n",
    "            use_regularizer : {bool} use penalization or not\n",
    "            C               : {int} penalization coeff\n",
    "            clip            : {bool} use gradient clipping or not\n",
    "       \n",
    "        Returns:\n",
    "            accuracy and losses of the model\n",
    " \n",
    "      \n",
    "        \"\"\"\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    for i in range(epochs):\n",
    "        print(\"Running EPOCH\",i+1)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        correct = 0\n",
    "       \n",
    "        for batch_idx,train in enumerate(train_loader):\n",
    " \n",
    "            attention_model.hidden_state = attention_model.init_hidden()\n",
    "            x,y = Variable(train[0]),Variable(train[1])\n",
    "            y_pred,att = attention_model(x)\n",
    "           \n",
    "            #penalization AAT - I\n",
    "            if use_regularization:\n",
    "                attT = att.transpose(1,2)\n",
    "                identity = torch.eye(att.size(1))\n",
    "                identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,att.size(1),att.size(1)))\n",
    "                penal = attention_model.l2_matrix_norm(att@attT - identity)\n",
    "\n",
    "            #binary classification\n",
    "            #Adding a very small value to prevent BCELoss from outputting NaN's\n",
    "            correct+=torch.eq(torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)),y).data.sum()\n",
    "            if use_regularization:\n",
    "                try:\n",
    "                    loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1)+1e-8,y) + C * penal/train_loader.batch_size\n",
    "\n",
    "                except RuntimeError:\n",
    "                    raise Exception(\"BCELoss gets nan values on regularization. Either remove regularization or add very small values\")\n",
    "            else:\n",
    "                loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y)\n",
    "               \n",
    " \n",
    "            total_loss+=loss.data\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "           \n",
    "            #gradient clipping\n",
    "            if clip:\n",
    "                torch.nn.utils.clip_grad_norm(attention_model.parameters(),0.5)\n",
    "            optimizer.step()\n",
    "            n_batches+=1\n",
    "           \n",
    "        print(\"avg_loss is\",total_loss/n_batches)\n",
    "        print(\"Accuracy of the model\",int(correct)/(n_batches*train_loader.batch_size))\n",
    "        losses.append(total_loss/n_batches)\n",
    "        accuracy.append(int(correct)/(n_batches*train_loader.batch_size))\n",
    "        \n",
    "        \n",
    "    return losses, accuracy\n",
    " \n",
    "def evaluate(attention_model, x_test, y_test):\n",
    "    \"\"\"\n",
    "        cv results\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            x_test          : {nplist} x_test\n",
    "            y_test          : {nplist} y_test\n",
    "       \n",
    "        Returns:\n",
    "            cv-accuracy\n",
    " \n",
    "      \n",
    "    \"\"\"\n",
    "   \n",
    "    attention_model.batch_size = x_test.shape[0]\n",
    "    attention_model.hidden_state = attention_model.init_hidden()\n",
    "    x_test_var = Variable(torch.from_numpy(x_test).type(torch.LongTensor))\n",
    "    y_test_pred,_ = attention_model(x_test_var)\n",
    "    \n",
    "    y_preds = torch.round(y_test_pred.type(torch.DoubleTensor).squeeze(1))\n",
    "    y_test_var = Variable(torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
    "    \n",
    "    print(classification_report(y_test, y_preds.detach().numpy()))\n",
    "    return int(torch.eq(y_preds,y_test_var).data.sum())/x_test_var.size(0)\n",
    " \n",
    "def get_activation_wts(attention_model,x):\n",
    "    \"\"\"\n",
    "        Get r attention heads\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            x               : {torch.Variable} input whose weights we want\n",
    "       \n",
    "        Returns:\n",
    "            r different attention weights\n",
    " \n",
    "      \n",
    "    \"\"\"\n",
    "    attention_model.batch_size = x.size(0)\n",
    "    attention_model.hidden_state = attention_model.init_hidden()\n",
    "    _,wts = attention_model(x)\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:26:43.214269Z",
     "start_time": "2019-08-22T01:26:43.201276Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 10\n",
    "attention_model = StructuredSelfAttention(batch_size=train_loader.batch_size,\n",
    "                                          lstm_hid_dim=50,\n",
    "                                          d_a=100,\n",
    "                                          r=10,\n",
    "                                          vocab_size=VOCAB_SIZE, \n",
    "                                          max_len=MAX_LEN,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:28:57.950163Z",
     "start_time": "2019-08-22T01:26:44.502530Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss is tensor(0.7818, dtype=torch.float64)\n",
      "Accuracy of the model 0.5360331632653061\n",
      "Running EPOCH 2\n",
      "avg_loss is tensor(0.7634, dtype=torch.float64)\n",
      "Accuracy of the model 0.6004464285714286\n",
      "Running EPOCH 3\n",
      "avg_loss is tensor(0.7427, dtype=torch.float64)\n",
      "Accuracy of the model 0.610969387755102\n",
      "Running EPOCH 4\n",
      "avg_loss is tensor(0.7289, dtype=torch.float64)\n",
      "Accuracy of the model 0.6243622448979592\n",
      "Running EPOCH 5\n",
      "avg_loss is tensor(0.7169, dtype=torch.float64)\n",
      "Accuracy of the model 0.6371173469387755\n",
      "Running EPOCH 6\n",
      "avg_loss is tensor(0.7054, dtype=torch.float64)\n",
      "Accuracy of the model 0.6492346938775511\n",
      "Running EPOCH 7\n",
      "avg_loss is tensor(0.6936, dtype=torch.float64)\n",
      "Accuracy of the model 0.6559311224489796\n",
      "Running EPOCH 8\n",
      "avg_loss is tensor(0.6814, dtype=torch.float64)\n",
      "Accuracy of the model 0.6648596938775511\n",
      "Running EPOCH 9\n",
      "avg_loss is tensor(0.6690, dtype=torch.float64)\n",
      "Accuracy of the model 0.6747448979591837\n",
      "Running EPOCH 10\n",
      "avg_loss is tensor(0.6566, dtype=torch.float64)\n",
      "Accuracy of the model 0.6871811224489796\n",
      "Running EPOCH 11\n",
      "avg_loss is tensor(0.6441, dtype=torch.float64)\n",
      "Accuracy of the model 0.6980229591836735\n",
      "Running EPOCH 12\n",
      "avg_loss is tensor(0.6314, dtype=torch.float64)\n",
      "Accuracy of the model 0.7139668367346939\n",
      "Running EPOCH 13\n",
      "avg_loss is tensor(0.6186, dtype=torch.float64)\n",
      "Accuracy of the model 0.7260841836734694\n",
      "Running EPOCH 14\n",
      "avg_loss is tensor(0.6055, dtype=torch.float64)\n",
      "Accuracy of the model 0.735969387755102\n",
      "Running EPOCH 15\n",
      "avg_loss is tensor(0.5923, dtype=torch.float64)\n",
      "Accuracy of the model 0.7445790816326531\n",
      "Running EPOCH 16\n",
      "avg_loss is tensor(0.5792, dtype=torch.float64)\n",
      "Accuracy of the model 0.7506377551020408\n",
      "Running EPOCH 17\n",
      "avg_loss is tensor(0.5661, dtype=torch.float64)\n",
      "Accuracy of the model 0.7576530612244898\n",
      "Running EPOCH 18\n",
      "avg_loss is tensor(0.5528, dtype=torch.float64)\n",
      "Accuracy of the model 0.767219387755102\n",
      "Running EPOCH 19\n",
      "avg_loss is tensor(0.5391, dtype=torch.float64)\n",
      "Accuracy of the model 0.7815688775510204\n",
      "Running EPOCH 20\n",
      "avg_loss is tensor(0.5256, dtype=torch.float64)\n",
      "Accuracy of the model 0.7879464285714286\n",
      "Running EPOCH 21\n",
      "avg_loss is tensor(0.5121, dtype=torch.float64)\n",
      "Accuracy of the model 0.7975127551020408\n",
      "Running EPOCH 22\n",
      "avg_loss is tensor(0.4984, dtype=torch.float64)\n",
      "Accuracy of the model 0.8045280612244898\n",
      "Running EPOCH 23\n",
      "avg_loss is tensor(0.4843, dtype=torch.float64)\n",
      "Accuracy of the model 0.8169642857142857\n",
      "Running EPOCH 24\n",
      "avg_loss is tensor(0.4709, dtype=torch.float64)\n",
      "Accuracy of the model 0.8227040816326531\n",
      "Running EPOCH 25\n",
      "avg_loss is tensor(0.4583, dtype=torch.float64)\n",
      "Accuracy of the model 0.829719387755102\n",
      "Running EPOCH 26\n",
      "avg_loss is tensor(0.4455, dtype=torch.float64)\n",
      "Accuracy of the model 0.8373724489795918\n",
      "Running EPOCH 27\n",
      "avg_loss is tensor(0.4333, dtype=torch.float64)\n",
      "Accuracy of the model 0.84375\n",
      "Running EPOCH 28\n",
      "avg_loss is tensor(0.4218, dtype=torch.float64)\n",
      "Accuracy of the model 0.8536352040816326\n",
      "Running EPOCH 29\n",
      "avg_loss is tensor(0.4088, dtype=torch.float64)\n",
      "Accuracy of the model 0.8625637755102041\n",
      "Running EPOCH 30\n",
      "avg_loss is tensor(0.3978, dtype=torch.float64)\n",
      "Accuracy of the model 0.8746811224489796\n",
      "Running EPOCH 31\n",
      "avg_loss is tensor(0.3872, dtype=torch.float64)\n",
      "Accuracy of the model 0.8781887755102041\n",
      "Running EPOCH 32\n",
      "avg_loss is tensor(0.3784, dtype=torch.float64)\n",
      "Accuracy of the model 0.8855229591836735\n",
      "Running EPOCH 33\n",
      "avg_loss is tensor(0.3706, dtype=torch.float64)\n",
      "Accuracy of the model 0.8880739795918368\n",
      "Running EPOCH 34\n",
      "avg_loss is tensor(0.3644, dtype=torch.float64)\n",
      "Accuracy of the model 0.8925382653061225\n",
      "Running EPOCH 35\n",
      "avg_loss is tensor(0.3557, dtype=torch.float64)\n",
      "Accuracy of the model 0.8960459183673469\n",
      "Running EPOCH 36\n",
      "avg_loss is tensor(0.3488, dtype=torch.float64)\n",
      "Accuracy of the model 0.8960459183673469\n",
      "Running EPOCH 37\n",
      "avg_loss is tensor(0.3401, dtype=torch.float64)\n",
      "Accuracy of the model 0.9011479591836735\n",
      "Running EPOCH 38\n",
      "avg_loss is tensor(0.3278, dtype=torch.float64)\n",
      "Accuracy of the model 0.9033801020408163\n",
      "Running EPOCH 39\n",
      "avg_loss is tensor(0.3183, dtype=torch.float64)\n",
      "Accuracy of the model 0.9088010204081632\n",
      "Running EPOCH 40\n",
      "avg_loss is tensor(0.3050, dtype=torch.float64)\n",
      "Accuracy of the model 0.9126275510204082\n",
      "Running EPOCH 41\n",
      "avg_loss is tensor(0.2907, dtype=torch.float64)\n",
      "Accuracy of the model 0.9170918367346939\n",
      "Running EPOCH 42\n",
      "avg_loss is tensor(0.2848, dtype=torch.float64)\n",
      "Accuracy of the model 0.9199617346938775\n",
      "Running EPOCH 43\n",
      "avg_loss is tensor(0.2888, dtype=torch.float64)\n",
      "Accuracy of the model 0.923469387755102\n",
      "Running EPOCH 44\n",
      "avg_loss is tensor(0.2796, dtype=torch.float64)\n",
      "Accuracy of the model 0.9257015306122449\n",
      "Running EPOCH 45\n",
      "avg_loss is tensor(0.2725, dtype=torch.float64)\n",
      "Accuracy of the model 0.9317602040816326\n",
      "Running EPOCH 46\n",
      "avg_loss is tensor(0.2703, dtype=torch.float64)\n",
      "Accuracy of the model 0.9311224489795918\n",
      "Running EPOCH 47\n",
      "avg_loss is tensor(0.2694, dtype=torch.float64)\n",
      "Accuracy of the model 0.9317602040816326\n",
      "Running EPOCH 48\n",
      "avg_loss is tensor(0.2661, dtype=torch.float64)\n",
      "Accuracy of the model 0.9330357142857143\n",
      "Running EPOCH 49\n",
      "avg_loss is tensor(0.2747, dtype=torch.float64)\n",
      "Accuracy of the model 0.9288903061224489\n",
      "Running EPOCH 50\n",
      "avg_loss is tensor(0.2537, dtype=torch.float64)\n",
      "Accuracy of the model 0.9371811224489796\n",
      "Running EPOCH 51\n",
      "avg_loss is tensor(0.2462, dtype=torch.float64)\n",
      "Accuracy of the model 0.9381377551020408\n",
      "Running EPOCH 52\n",
      "avg_loss is tensor(0.2391, dtype=torch.float64)\n",
      "Accuracy of the model 0.9426020408163265\n",
      "Running EPOCH 53\n",
      "avg_loss is tensor(0.2334, dtype=torch.float64)\n",
      "Accuracy of the model 0.9461096938775511\n",
      "Running EPOCH 54\n",
      "avg_loss is tensor(0.2294, dtype=torch.float64)\n",
      "Accuracy of the model 0.9483418367346939\n",
      "Running EPOCH 55\n",
      "avg_loss is tensor(0.2290, dtype=torch.float64)\n",
      "Accuracy of the model 0.9461096938775511\n",
      "Running EPOCH 56\n",
      "avg_loss is tensor(0.2337, dtype=torch.float64)\n",
      "Accuracy of the model 0.9445153061224489\n",
      "Running EPOCH 57\n",
      "avg_loss is tensor(0.2156, dtype=torch.float64)\n",
      "Accuracy of the model 0.9496173469387755\n",
      "Running EPOCH 58\n",
      "avg_loss is tensor(0.2086, dtype=torch.float64)\n",
      "Accuracy of the model 0.9518494897959183\n",
      "Running EPOCH 59\n",
      "avg_loss is tensor(0.2040, dtype=torch.float64)\n",
      "Accuracy of the model 0.9537627551020408\n",
      "Running EPOCH 60\n",
      "avg_loss is tensor(0.1987, dtype=torch.float64)\n",
      "Accuracy of the model 0.9537627551020408\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(attention_model.parameters())\n",
    "\n",
    "losses, accuracy = train(attention_model, train_loader, loss, optimizer, epochs=60,\n",
    "                         use_regularization=True, C=0.03, clip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:28:58.932600Z",
     "start_time": "2019-08-22T01:28:57.955159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       524\n",
      "           1       0.72      0.82      0.77       524\n",
      "\n",
      "    accuracy                           0.75      1048\n",
      "   macro avg       0.76      0.75      0.75      1048\n",
      "weighted avg       0.76      0.75      0.75      1048\n",
      "\n",
      "0.7509541984732825\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(attention_model, tokenized_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:24:10.034931Z",
     "start_time": "2019-08-22T01:24:10.022936Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_attention(wts, X_test, filename):\n",
    "    wts_add = torch.sum(wts, 1)\n",
    "    wts_add_np = wts_add.data.numpy()\n",
    "    wts_add_list = wts_add_np.tolist()\n",
    "    text = []\n",
    "    for test in X_test:\n",
    "        text.append(\" \".join(test))\n",
    "    createHTML(text, wts_add_list, filename)\n",
    "    print(\"Attention visualization created for {} samples\".format(len(X_test)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:36:06.404405Z",
     "start_time": "2019-08-22T01:36:06.378418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qmqidi님,1,000원 그라샤! - 안녕하세요 브베님 저희 업체 스폰 제의를 드리고 싶습니다 저희는 가발과 흑채를 판매하는 업체로 브베님 남은 옆머리 싹다 밀어버리는 조건으로 광고 제의를 하고싶습니다 하고싶으시다면 문의는 필승 안마방 김실장에게 남겨주세요\\t',\n",
       "       '겁나 열심히 보신', '아 쎄발 아', '같은베개나 불러 씨1발', '크라운 젠혐?', 'gay',\n",
       "       '깨물이 개킹받네 ㅋㅋㅋㅋㅋ', 'ㅋㅋㅋㅋ쌍베 표점 꿀잼!', '개웃기네ㅋㄱㄱㅋ', '저새끼 서순', '개못핵당했네',\n",
       "       '이게 방찐이지', '개 꿀', '니들 어허 소리 들으려고 천원씩 꼬라박냐 ??', '진짜 개못해',\n",
       "       '툭하면 말돌리고 돈안벌리면 방송 빡종하고', '팀원이 개못하네 ㄹㅇ', '쫄?', '파벳 졸 커보이네 ㅋ', '앵간',\n",
       "       '다딱이들 딜러 칼픽 ㄷㄷ', 'ㅈ냥이', '오빠 밟아', 'ㅇㅅㅂㅅ', 'ㄴㅈ', '브베미애장년', '수면 잘때렸다',\n",
       "       '리듬 처 타시네 ㅋㅋㅋㅋㅋ', '주작;;', 'ㅇㅈㄹㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '저정도면 조카 쌉가능인데', '뿌직',\n",
       "       '더빙 개꿀잼', '농락잼', '저건 맨날 맞네 ㅋㅋ', '색맹새기', '강냉이 털어버려', '쪼젼', '브베스트',\n",
       "       '다정아 나랑 맞다이뜨자 니가 브사모대표로 나와', '미친', '아좀닥쳐라씨발련아', '허나 ㅈ냥이일뿐',\n",
       "       '브베야 집에일이생겼는데 트위치에서 거임하고자빠졌냐 이구라쟁이', 'ㅇㅅㅄㅋㅋㅋㅋㅋㅋㅋ',\n",
       "       '난이도 올라가야 죽을가봐 쫄깃한데', '야레기들', '폴팔이 중고차팔이도 그리죠', '아 불편 ㅡㅡ',\n",
       "       '저놈 발기부전인가봐', '9질9질', '누나 나 죽어 ㅋㅋㅋㅋㅋㅋ', '작업러인지는 본인만 아는거고 비하 ㄴㄴ',\n",
       "       '잘들린다고 장애년아', '똥까루를 뿌려', '뇌절 파티', '진정한 탑신병자다',\n",
       "       '속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망 속/보/노/무/현/사/망',\n",
       "       '엄마없...', '?? 사칭미팅넝', '집단린치', '찐베등장',\n",
       "       '근데 그냥 안깨고 5명 몰려다니면서 개패기 가능 ?', '지리고오지고렛잇고알파고', '나니ㅣㅣㅣㅣㅣㅣㅣㅣ',\n",
       "       '왕깨러 브베아빠 장례식장 가야지', '개모대', '목소리 진짜 ㅈ@같너ㅔ', '가붕가붕',\n",
       "       '브베스트 영정먹음?ㅋㅋㅋㅋㅅㅂ', '당신이 죽엿어', 'ㄴㄷㅆ!!', '뭐하냐 ㅂㅅ아??',\n",
       "       '브베형 어꿍이억울해요ㅜㅇㅜ어꿍이서러워요', '죽는다', 'ㄲㅂ', '존버타이밍 ㅋㅋ',\n",
       "       '어휴 어떤 프로불편러가 ㅉㅉ;;', '죽순좌 몸매 ㄷㄷㄷ', 'ㄹㅇ꼬우면 독립하던가네', '스태미너봐 파오후지',\n",
       "       '범어리형씨 개좋아하네',\n",
       "       '브베형 이번에 여중딩한테 다리사진 보여달라고 카톡한거 인터넷뉴스에 떴어요 해명 좀 확실하게 해주세요~~~브베형 이번에 여중딩한테 다리사진 보여달라고 카톡한거 인터넷뉴스에 떴어요 해명 좀 확실하게 해주세요~~~브베형 이번에 여중딩한테 다리사진 보여달라고 카톡한거 인터넷뉴스에 떴어요 해명 좀 확실하게 해주세요~~~',\n",
       "       'ㅇㅅㅂㅅ', 'ㅈ냥이', 'ㅗ', '키워서 먹어 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '점멸 아끼려다 죽었다', 'ㅗㅜㅑ',\n",
       "       '매일마다 어꿍이를 박아주느라 생긴 브베의 근육!!!!!', '빠가닉', 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 조졌다',\n",
       "       'beubedie님1000원 그라샤! - 브베야 어제 커터칼로 손목 그엇는데 못죽었어 자살이라는게 쉽지 않더라 저번주에는 수면제를 먹어봤는데 너무 고통스러웠어 이제 어떻게 이 지긋지긋한 삶을 끝낼수 있을까? 누가 도로에서 날 밀어줬으면 좋겠어',\n",
       "       '종신형 처해도 ㅇㅈ', '내려 ㅇㅅㄲㅇ', '무친', '건설은 형이 아래까지 해줘야해요', '노팬티맨 ㅗㅜ',\n",
       "       '40살 먹고 조카뻘들한테 도--네로 욕이나 쳐먹으며 사는게 좋냐??', 'ㅇㅅㅂㅅ!ㅇㅅㅂㅅ!ㅇㅅㅂㅅ!ㅇㅅㅂㅅ!',\n",
       "       '표정봐라 가관이네', '쉿', '오빠 목소리 꼴릿하샤', '죽통날아가도 인정입니다 허허', '이시국에 연애질이라니',\n",
       "       '폭 to the 동', '<<1라때 자낳괴함', '겜 터졌다', '질내가 좋다잖아',\n",
       "       '그 고추에 깔때기 달고있는애들', '닉값보소', '개노잼', '뽕비트 ㄷㄷ', '논란 안생기게 철저히 여장해주세용',\n",
       "       '싸엘레싸', '챗창 돌창났네ㅋㅋ', '개뜬금없네 ㅋㅋ', '엉덩이를 찌르는 기둥 ㅋㅋㅋ', 'ㄴㄷ^^', '조시다',\n",
       "       '면 상 바 주 카', '브베 대가리론 언더테일 못해 임마', '이건 안이지 ㅡㅡ개억지야',\n",
       "       '두시기 쓸개즙이잖아 맨날 구라쳐', '럭스 꺼어어어어억', '찐베 안오나??',\n",
       "       '브베 고츄에 쵸코렛 무쵸소 조ㄴ나 빠루고 시프다 개시바루 대머리새퀴 구리고 사타구니에 내 어루구루 바가서 내므세 마꼬싶다 야아아 기붕조타 기모찌잉 기모찡 기머찌이잉 ~ 무우끼냐 우켜 쉬바대머리쇜기야 고츄우우우우고츙~브베 고츄에 쵸코렛 무쵸소 조ㄴ나 빠루고 시프다 개시바루 대머리새퀴 구리고 사타구니에 내 어루구루 바가서 내므세 마꼬싶다 야아아 기붕조타 기모찌잉 기모찡 기머찌이잉 ~ 무우끼냐 우켜 쉬바대머리쇜기야 고츄우우우우고츙~브베 고츄에 쵸코렛 무쵸소 조ㄴ나 빠루고 시프다 개시바루 대머리새퀴 구리고 사타구니에 내 어루구루 바가서 내므세 마꼬싶다 야아아 기붕조타 기모찌잉 기모찡 기머찌이잉 ~ 무우끼냐 우켜 쉬바대머리쇜기야 고츄우우우우고츙~',\n",
       "       '앙 저지불까띠', '개 좋음 복지시설', '혐키', 'ㅋㅋㅋㅋㅋㅋㅁㅊ', '언제죽어', '애미뒤진 얘기 그만해라',\n",
       "       '개좋아해 ㅋㅋㅋ', '개혜자네', '똑같은거 하면 쳐맞는다', '개잘해 서로',\n",
       "       '로리타 중독자새끼야 너 빨리 신원조회해서 범죄기록없는지 보여줘라 혜화중학생 3학년 3반 사건 잊었냐 벌써?',\n",
       "       '운영당할바에 싸우지 그냥', '뇌절 ㅋㅋ', '개웃기네 ㅋㅋㅋㅋㅋㅋㅋ', '개추하게 죽음 ㅋㅋㅋ',\n",
       "       '마린 다 죽어욧', 'ㄸ바', '근데 원딜이 제대로 조죴네', '리페어 개사기 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '개소리야',\n",
       "       '으악 잔인', '항문편지', '여러분 돈 그만 쏘세요 이 씨벌럼 돈쳐먹고 사는거 보기 좆같습니다',\n",
       "       '녹슬아 사랑해 영차 영차 억억 옷슬아', '아니 진짜 킹부러야?', '새봄추', '다음판에 같은편으로 만나면 개꿀잼',\n",
       "       '형님 또 죽겠습니다', '옵저버 ㅅ세기', 'ㄹㅇ 개쌘조합이다', '쫄보 애반데', '형은 진짜 관에...',\n",
       "       '브베형 어꿍이고소해도됭 무기징역받을자신있어요ㅜㅇㅜ', '자야 미쳤는데 저거 우예잡음', 'ㅈ따뚜이', '애반데',\n",
       "       '진짜 창석이형 스타듀벨리하는거 보면 암걸려 뒤져버릴꺼같으니까 제발 다른거해', '끔찍하다',\n",
       "       '브베는 지금 당장 인육치킨을 해명하라', '가버렷', '갓구리 ㄷㄷ', 'ㄷㅈ', '눈까러',\n",
       "       '아니 브베 씨발아 영어 좆도 못하면 DLC 사서 한국어로 하라고', '밸붕', 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ개웃',\n",
       "       '섹', '가붕아', '진짜 빠꾸가 없네', '변수는 개뿔', '이거 개웃김 ㅋㅋㅋㅋ', '트런들 개똥챔;',\n",
       "       '데스노트지리네', '아 개역겹누', 'ㅗ', '오 답ㅆㅂ뿌셔', '개어거진데',\n",
       "       '개꿀잼이네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '불타는 효녀 ㄷㄷ', '노 퓨 쳐', '나가죽어~~',\n",
       "       'ㅇㅅㅂㅅ', '망가뿐이었어', 'ㅈ망', '배만튀 좋다', '배개딸', '미애폭행 타임',\n",
       "       '모두들 ㄲㅈ 한번씩 부탁드립니다', '책마렵놐ㅋㅋㅋㅋㅋ', '나이 40에 노안에 야맹증있냐?', '인육치킨집',\n",
       "       '표정 미쳤네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ', 'ㅇㅈ', '옦뜨라 따랑해', '닉값ㅋㅋㅋㅋ', '단단해지면 커진다고??? ㅗㅜㅑ',\n",
       "       'ㅁㅊ', 'ㄲㅈ', '씨발대머리년ㅋㅋㅋㅋㅋㅋㅋ', '너구리 데스무비 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '조졌는데요?',\n",
       "       '펄 손절', '도 네 섹 스', '걍 뇌가 없는거야', '조졌다 ㄹㅇ',\n",
       "       '아 내일 군대 ㅅㅂ 브베 욕듣는거 한동안 못보내 ㅜㅜ', '으 왜자꾸 끊겨', '개웃기네 ㅋㅋ',\n",
       "       '멜탈 터진다 ㅋㅋㅋ', '읽고 싶은 것만 읽노 ㅋㅋㅋ', '아 미칀', '섹', '섹',\n",
       "       '아프리카에서나 여기서나 욕ㅊㅕ먹는건 매한가지네',\n",
       "       '마르아라님1000원 그라샤! - 애들아 페폭으로 창석이 맨틀 무너트리는거 거의 불가능하다 이세끼 살면서 유일하게 보이는 제능이 욕받지다 패드립에 웃는거 못봤냐? 그냥 매모장 펴서 하고싶은말 적고 참아라 진짜 참아서 이세끼 멸망하는거 보고싶다',\n",
       "       '병신인가진짜', '일=안마방', '버그ㅈ망겜', '더럽게 못하네', '아니 개잘해 ㅋㅋㅋㅋ', '역시 밥신',\n",
       "       'ㄴ ㅏㄱ ㅏ', '브베양 다음 친구비 수금일은 언제냐궁 오늘 내면 댕 ? ', 'ㅇㅈ',\n",
       "       '인육치킨이 사실이었나 보네요 브베형', '당명지 넘 재수없어', '누나 나가죽어~~',\n",
       "       '브베야 오늘 얼마 수금했냐 씨발련나', '풔킹~!', '어쩐지 유툽갔는대 없다해더니 ㅗ', '개나빠 진짜',\n",
       "       '병1신 쪼꼬미도 너 맞아야 사람된다는데??ㅋㅋㅋㅋㅋㅋ', '씹 노 잼', '미친놈들ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       "       '와 아프리카 제끼고 트위치 킨거냐? 이시바럼', '앙 기모띠', '혐', '미애 또 때렸냐', '콩까지마 콩까지마',\n",
       "       '비응신아 irl이 캠방송 카테고리다', 'ㅈ냥이', '지렸다', '쌍베 분노의 버거이벤트 ㄱㄱㄱㄱㄱㄱ',\n",
       "       '까자 ㅎㅎ', '야겜?', '섹4', '갑분싸', '자.지', '병ㅡ신ㅡ새ㅡ끼', '꼰', '병신맞음', '존잘',\n",
       "       '짬타 말라죽네', '브베 영어 발음 너무 쎅쓰하샤 !', '찐임ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '개조졌다',\n",
       "       '브베 죽이고싶다', '도벽 달달', '욕하자~', '오 ㅡㅡㅡㅡㅡㅡㅡ 열', '병 형신이래 ㅌㅌㅋㅋㅋㅋㅋ',\n",
       "       '5252벌써죽는다구?', '창ㅡㅡㅡㅡㅡㅡㅡ렬', '남혐 상베 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '쌌네 쌋어',\n",
       "       '이거 성공하니까 배치기가 이후 노래들에 뽕끼를 계속 넣음', 'ㅁㅊ준', '손가락 비엔나',\n",
       "       '아니 저도 피시방 알바해봤는데 ㄹㅇ 엠창들 개많음', '연기오지고', '안죽어 이건', '탑신병자들', '조졋다',\n",
       "       '따억힐듯', '개넉네', '섹', '탈리야 아까 만났던놈 같은데', '트월킹을 춰야하는 부분',\n",
       "       '개사 개잘했네 ㅋㅋㅋ', '미애', '빠따들어!!', '나락충;', '선넘어 ㅇㅈㄹㅋㅋㅋ',\n",
       "       '3분전에 빤스런 누가했더라', '무친판단 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', 'ㅋㅋㅋㅋㅋㅋ 미췬',\n",
       "       '일베동료들한테 고민상담중이세요.. 이분 일베하시거든요', '혐션행 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '슈팅겜 미쳤네 ㅋㅋㅋㅋ',\n",
       "       '겜은 엉성한데 개지밌네', '졷포에라', '딱복은 ㅇㅈ이지', '사일 궁 미쳤다', '꽤 오래버텻노',\n",
       "       '선채로죽었어', '권능 도랏맨', '아붕아 ㅠㅠㅠ', '가챠겜 극혐;',\n",
       "       '똑같이만들어서하는중인데 제피르스가 진짜 십사기 ㅋㅋㅋ', '배울때도 실력숨기는 ㅅㄲ', '베이가 개이득',\n",
       "       'ㅁㅊㅆ?', '개불쌍하네 ㅋㅋㅋㅋ', 'ㅈ냥이 ㄷㄷ', '그거 큐혐이야', 'ㅇ ㅅ ㅂ ㅅ', '너무 빡세다',\n",
       "       '와 자원봐 개많다', '가붕!', '개웃기다', '루시안 무빙해서 탱킹 개쩔었다', '조졌네',\n",
       "       '진짜 창석이형 스타듀벨리하는거 보면 암걸려 뒤져버릴꺼같으니까 제발 다른거해', '또죽', 'ㅈ냥이가먹었어',\n",
       "       '또 죽는구만', '개짧은데', '브베뽕 너무 착하샤~~', 'ㅈ시계 ㄹㅇ 삭제좀', 'ㅉㅉ ㅉ ㅉㅉ', '찍',\n",
       "       '대나무숲 불지르기', '보끄랍노 ㅋㅋㅋㅋ 커엽네', '싫어요 개많아', '한창우 닉 ㅆㅅㅌㅊㅋㅋㅋ', '개잘핵',\n",
       "       '쌌냐고', 'ㅗ', '너무 ㄴㄷㅆ', '누나 쟤죽어', '박미애 검은봉지에 정ㅡㅡ액 발싸',\n",
       "       '아 일일히 더빙질은 왜쳐하는거야 목소리도 조까트면서', '개열받네', '에반데',\n",
       "       '님이 브베의 부름을 받아 당신을 치킨으로 만들어 버리겠노라 결심했습니다. !', '미네랄 살살녹는다', '개꿀잼 겜',\n",
       "       '병신진짜 ㅋㅋㅋ', '개짱나는 귀신 ㅋㅋㅋ', 'ㅇㅅㅂㅅ', '왜알켜주냐고 브사모 병 ㅂ신새끼들아~',\n",
       "       '혐리건 수준', '메딕이아니라 호딕이네', '아 빡치네', '시발련아 빨리 처먹기나해', '또 죽는다',\n",
       "       '커즈 말라죽는다', '아씨~발련이 스파게티먹고있는데 존~나더럽네', 'ㅁㅊ ㅅㄲ네', '지렸다는 게 학계의 정설',\n",
       "       '니가하는게 음악이냐 병신아', 'ㄴㄷㅆ', '브베배 칼빵', '미ㅡ애', '스킨빨', '에반데', '창석이 형 쌌네',\n",
       "       '넌이미죽어있다', '아니 창석이형 진짜 나 개 무시하지말고 스타듀벨리말고 다른거하라고 답답하니까', '등신장비',\n",
       "       '다정이 애ㅡ미 뒤짐', '망했어요', '냉동대지는 벌써 개발 됌', '속상맨', '개재밌는데',\n",
       "       '미친 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '터졌네', '가붕이는 봇에서 캣타워로쓰자', '해리포터 뭔데 ㅁㅊ',\n",
       "       '노1무1현이 욕임?? 왜 밴을', '조까는 소리하고있농ㅋㅋ', '와 개좋다', '장막개크네', '빵구뿡',\n",
       "       '존버 ㅋㅋ',\n",
       "       '옛날에 세상에 이런일이 였나?? 스펀지 였나? 그런 프로에 매운맛 달인 아줌마 나왔었는데 그분 먹는게 참 5G던데',\n",
       "       '독거노인 이룬호 ㅋㅋ', '죽이고싶은 주먹감자쟁이', '생각 없는거 ㄹㅇ',\n",
       "       '아프읍읍 늦게킨다더니 이지랄하고있네 쓰렉새끼', '변명 지렸습니다 형님',\n",
       "       '나 브베 자쥐 빨고 싶어 헥헥 나 강간해됴~♡♡하흥', '개이득이지', '쓰레기새끼야', '쌍하다 추베야',\n",
       "       '날로 먹네 이걸', '기보배다 ㅋㅋㅋ', '애로?', '갓리드', '지랄마 병신아', '똥꾜터지겠다',\n",
       "       '옵저버 넌씨눈', '뇌절케넨', '할배 죽었나봐', '사람미침 진짜', 'ㅠㅠ늙병쌍',\n",
       "       '브베님 어제 신음소리 창석이 어머니 줘패는 소리인가요? 해명해주세요', '니가 너무해 시바려나ㅋㅋㅋ',\n",
       "       '밥렐리아 가즈아', '큐혐 ㅋㅋㅋㅋㅋ', '겐지가 이렇게 호9캐였나', '이판개오래하네', '염병?',\n",
       "       'ㅁㅊ ㅋㅋㄲ', '케이티 화이팅!!!!!ㅡㅡㅡㅡ', '먹고해라 쌍1놈아', '파랑 정치 오지게잘하네 ㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       "       '병신이라고우리가?', '그냥 딱 봐도 ㄴㄷㅆ 이네', '가붕아....', 'ㅅㅅㅂ 노무 야한데',\n",
       "       '아이작 할바에 미애를 때려라', '빤스런', '개드립 필요없습니다 견찰서에서 직접보시죠', '형이 죽였어',\n",
       "       '앙대 그만해라 시@@@발', '도둑놈 처럼 죽었네 ㅋㅋ', '까붕다가 망했죠', '틀헉 ㅋㅋㅋㅋ',\n",
       "       '간나색히 젠부샤스!', '아 씨1발아 쩝쩝대면서 먹지마', '진짜 개나빴다 ㅋㅋㅋㅋㅋ', '십 노 잼', 'ㅈ냥이',\n",
       "       '미쳤드 ㅋㅋㅋㅋㅋㅋㅋㅋ', '그 종족특) 영어로 말해주면 답변못함', '빠개짐', '개웃겨 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       "       '노머고 길냥이 컷', 'ㅈㅈ인뎆ㅈ',\n",
       "       '아니 창석이형 진짜 나 개 무시하지말고 스타듀벨리말고 다른거하라고 답답하니까.', '볼붕이 ㅋㅋㅋ', '얘바얘',\n",
       "       '아개듣기싫어 소름돋아', '재능충', '미띵놈 게임안할꺼면 머가리 노출방송 아프리카가라', '아조씨 뚜까맞ㅠㅠ',\n",
       "       '?? 초월급 스킨도 그따윈데 뭐가 나왔길래', '옥스리',\n",
       "       '진짜 창석이형 스타듀벨리하는거 보면 암걸려 뒤져버릴꺼같으니까 제발 다른거해', '지랄마 정품아니잖아', '애ㅔ에미',\n",
       "       'ㅇㅅㅂㅅ', '흑우?', '방찐 없는 방찐전사?', '촉수물 찍으러 가심', '고양이 확대범 ㅋㅋㅋㅋㅋㅋ',\n",
       "       '빠따의 계승자 피넛', '아르타니스 쉑보다 훨씬 그릇이 크심 ㅇㅈ?', '엠비션돼지',\n",
       "       '죽이고싶은 전기톱쟁이와 10선', '우리케틀 느그이즈', 'ㅇㅅㅄ', '개패고싶네', '똥겜중독', '찍!!',\n",
       "       '저새끼 살인미수야', '브베스트 정1지 위기 해명좀', 'ㄴㄷ^^',\n",
       "       'wns249877님1000원 그라샤! - 내가 니새끼 자살하거나 트위치에서 추방당하는 그날까지 힘 닫는대로 신고들어간다 진짜 넌 뭐하는새끼인데 도대체 이해가안간다 아니 세상에 베개를 가지고 딸을 치지를 않나 나이처먹고 자살빨리하는게 미애한테 효도하는 길이다 효도하자',\n",
       "       '유부남은 다 그래', '이 씨1발 진짜 도--네 안하니까 본척도 안하네 창석이형 스타듀벨리 끄자 하...',\n",
       "       '빠따치느라 설거지 할시간이어딧어', '얼라들은 지금 다 자구있어', '킹겐 개잘하네 ㅋㅋ', '짐: ㅗ', '미쳤다',\n",
       "       '게임이 조졌는데', '머야 죽이는건데', '대노 동영상 잘봤어요',\n",
       "       '혹시 휘피 애미도 미애냐 혹시 휘피 애미도 미애냐', 'ㄱㄵ', '도라인가', '매미의 맴맴은 아 ㅅㅅ하고싶다',\n",
       "       '쉰밥', '4랄부', '개잘해 ㅋㅋㅋㅋ', '온플릭 빡침', '랄부만 큰건 쓸데가 없자나',\n",
       "       '가정교육을 똥꾸멍으로 받으니까 맨날 약속 안지키지 ㅎㅎ', '개무서울듯 ㅋㅋㅋㅋ', '뇌내망상',\n",
       "       '박망파도 약빨 다해가네', '왜안와 십새기', '칸 쳐맞았네', '방찐 굴리면서 아직 8급인 사람이 있다? 뿌슝빠슝',\n",
       "       '갈리오가 먼저 죽을2ㅜㄹ이야', 'ㅁㅊ', '시청자가 까라고하면 까 시발아', '개멋있네 ㅋㅋ', 'ㅇㅅㅂㅅ',\n",
       "       '쉬다못해 곰팡이 슬었습니다', '안대잔아 ㅡㅡ', '개똥', '개아까움 ㅋㅋㅋㅋ', '와 ㅁㅊ', '켠왕 지렷다',\n",
       "       '우리 아들 왜이리 호구잡혔냐 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '용맞추고 형변맞추고 쉬바나 가갑2워모그 1개어떰 안뒤질꺼 같은디',\n",
       "       'ㄹㅇ 살인나자너', '바텀이 조져지는 버그!', 'ㅇㅈㅇㅈㅇㅈㄹㅇㄹㅇ', '좆같노', '가붕이가즈아ㅏㅏㅏㅏㅏㅏㅏㅏ',\n",
       "       '감금 ㅗㅜㅑ', '궁 겁나 아낌', '그냥 방송을꺼 돈에 환장한 놈아', '어꿍이 나쁜새1끼야',\n",
       "       '존나잘버티네 ㅋㅋㅋㅋ', '개웃김ㅋㅋㅋㅋ', '승딸아..', '브베 안마방 가지 못하게하자', '싸빨랑끼!',\n",
       "       'ㅅㅂ ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ', '오-바워치', '미애 브라 뺏으라감ㅋㅋ', '사일 리치베인가면 겁나쌤'],\n",
       "      dtype='<U360')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_test)[y_test==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:36:22.240340Z",
     "start_time": "2019-08-22T01:36:21.992481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention visualization created for 524 samples\n"
     ]
    }
   ],
   "source": [
    "test_last_idx = 800\n",
    "wts = get_activation_wts(attention_model,\n",
    "                         Variable(torch.from_numpy(tokenized_test[y_test==1][:test_last_idx]).type(torch.LongTensor)))\n",
    "# print(torch.sum(wts,1).data.numpy().tolist())\n",
    "visualize_attention(wts, np.array(X_test)[y_test==1][:test_last_idx], filename='attention.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:25:22.653374Z",
     "start_time": "2019-08-22T01:25:22.634382Z"
    }
   },
   "outputs": [],
   "source": [
    "#Credits to Lin Zhouhan(@hantek) for the complete visualization code\n",
    "import random, os, numpy, scipy\n",
    "from codecs import open\n",
    "def createHTML(texts, weights, fileName):\n",
    "    \"\"\"\n",
    "    Creates a html file with text heat.\n",
    "\tweights: attention weights for visualizing\n",
    "\ttexts: text on which attention weights are to be visualized\n",
    "    \"\"\"\n",
    "    fileName = \"visualization/\"+fileName\n",
    "    fOut = open(fileName, \"w\", encoding=\"utf-8\")\n",
    "    part1 = \"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "    <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\">\n",
    "    <style>\n",
    "    body {\n",
    "    font-family: Sans-Serif;\n",
    "    }\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h3>\n",
    "    Heatmaps\n",
    "    </h3>\n",
    "    </body>\n",
    "    <script>\n",
    "    \"\"\"\n",
    "    part2 = \"\"\"\n",
    "    var color = \"255,0,0\";\n",
    "    var ngram_length = 3;\n",
    "    var half_ngram = 1;\n",
    "    for (var k=0; k < any_text.length; k++) {\n",
    "    var tokens = any_text[k].split(\" \");\n",
    "    var intensity = new Array(tokens.length);\n",
    "    var max_intensity = Number.MIN_SAFE_INTEGER;\n",
    "    var min_intensity = Number.MAX_SAFE_INTEGER;\n",
    "    for (var i = 0; i < intensity.length; i++) {\n",
    "    intensity[i] = 0.0;\n",
    "    for (var j = -half_ngram; j < ngram_length-half_ngram; j++) {\n",
    "    if (i+j < intensity.length && i+j > -1) {\n",
    "    intensity[i] += trigram_weights[k][i + j];\n",
    "    }\n",
    "    }\n",
    "    if (i == 0 || i == intensity.length-1) {\n",
    "    intensity[i] /= 2.0;\n",
    "    } else {\n",
    "    intensity[i] /= 3.0;\n",
    "    }\n",
    "    if (intensity[i] > max_intensity) {\n",
    "    max_intensity = intensity[i];\n",
    "    }\n",
    "    if (intensity[i] < min_intensity) {\n",
    "    min_intensity = intensity[i];\n",
    "    }\n",
    "    }\n",
    "    var denominator = max_intensity - min_intensity;\n",
    "    for (var i = 0; i < intensity.length; i++) {\n",
    "    intensity[i] = (intensity[i] - min_intensity) / denominator;\n",
    "    }\n",
    "    if (k%2 == 0) {\n",
    "    var heat_text = \"<p><br><b>Example:</b><br>\";\n",
    "    } else {\n",
    "    var heat_text = \"<b>Example:</b><br>\";\n",
    "    }\n",
    "    var space = \"\";\n",
    "    for (var i = 0; i < tokens.length; i++) {\n",
    "    heat_text += \"<span style='background-color:rgba(\" + color + \",\" + intensity[i] + \")'>\" + space + tokens[i] + \"</span>\";\n",
    "    if (space == \"\") {\n",
    "    space = \" \";\n",
    "    }\n",
    "    }\n",
    "    //heat_text += \"<p>\";\n",
    "    document.body.innerHTML += heat_text;\n",
    "    }\n",
    "    </script>\n",
    "    </html>\"\"\"\n",
    "    putQuote = lambda x: \"\\\"%s\\\"\"%x\n",
    "    textsString = \"var any_text = [%s];\\n\"%(\",\".join(map(putQuote, texts)))\n",
    "    weightsString = \"var trigram_weights = [%s];\\n\"%(\",\".join(map(str,weights)))\n",
    "    fOut.write(part1)\n",
    "    fOut.write(textsString)\n",
    "    fOut.write(weightsString)\n",
    "    fOut.write(part2)\n",
    "    fOut.close()\n",
    "  \n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
